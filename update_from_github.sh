
#!/bin/bash

# =============================================================================
# UPDATE FROM GITHUB (Auto AI Setup)
# =============================================================================
# This script safely updates your local system from GitHub
# Automatically installs Ollama and downloads all required AI models
# Includes: libCEC, Ollama AI, Required Models, and Color Scheme Standardization
# =============================================================================

set -e

echo "ğŸ”„ Updating Sports Bar AI Assistant from GitHub..."

cd /home/ubuntu/Sports-Bar-TV-Controller

# Check git status
echo "ğŸ“Š Checking git status..."
git status

# Stop running processes
echo "â¹ï¸  Stopping running processes..."
pkill -f "npm.*start" 2>/dev/null || true
pkill -f "next" 2>/dev/null || true
sleep 2

# Pull latest changes
echo "â¬‡ï¸  Pulling latest changes from GitHub..."
# Handle any local database changes that might conflict
git checkout -- prisma/dev.db 2>/dev/null || true
git clean -fd uploads/ 2>/dev/null || true
git pull origin main

# Use npm instead of yarn to avoid version conflicts
echo "ğŸ“¦ Installing/updating dependencies with npm..."
npm install

# Check for and install libCEC if missing
if ! command -v cec-client &> /dev/null; then
    echo "ğŸ“º Installing HDMI-CEC support (libCEC)..."
    sudo apt update
    sudo apt install -y cec-utils libcec6 libcec-dev
    echo "âœ… libCEC installed successfully"
else
    echo "âœ… libCEC already installed"
fi

# =============================================================================
# OLLAMA AND AI MODELS INSTALLATION
# =============================================================================
echo ""
echo "ğŸ¤– Setting up Local AI (Ollama)..."
echo "=================================================="

# Install Ollama if not present
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¥ Ollama not found. Installing..."
    curl -fsSL https://ollama.com/install.sh | sh
    
    if [ $? -eq 0 ]; then
        echo "âœ… Ollama installed successfully"
    else
        echo "âŒ Failed to install Ollama"
        echo "   Please visit https://ollama.com/download for manual installation"
        exit 1
    fi
else
    echo "âœ… Ollama already installed"
fi

# Start Ollama service if not running
if ! pgrep -x "ollama" > /dev/null; then
    echo "ğŸ”„ Starting Ollama service..."
    ollama serve > /dev/null 2>&1 &
    sleep 3
    echo "âœ… Ollama service started"
else
    echo "âœ… Ollama service is running"
fi

# Define required models for all AI features
REQUIRED_MODELS=(
    "llama3.2"      # Primary model for style analysis and AI features
    "llama2"        # Backup model for device diagnostics
    "mistral"       # Fast model for quick queries
)

echo ""
echo "ğŸ“¥ Downloading required AI models..."
echo "   This may take a few minutes on first run..."

# Pull each required model
for MODEL in "${REQUIRED_MODELS[@]}"; do
    echo ""
    echo "ğŸ“¦ Checking model: $MODEL"
    
    if ollama list | grep -q "^$MODEL"; then
        echo "   âœ… $MODEL already available"
    else
        echo "   ğŸ“¥ Downloading $MODEL..."
        if ollama pull "$MODEL"; then
            echo "   âœ… $MODEL downloaded successfully"
        else
            echo "   âš ï¸  Warning: Could not download $MODEL"
            echo "      AI features may be limited"
        fi
    fi
done

echo ""
echo "ğŸ“‹ Installed AI Models:"
ollama list

echo ""
echo "âœ… AI setup complete!"

# Update database if schema changed
if [ -f "prisma/schema.prisma" ]; then
    echo ""
    echo "ğŸ—„ï¸  Updating database..."
    export DATABASE_URL="file:./dev.db"
    npx prisma generate
    npx prisma db push
fi

# Build the application
echo ""
echo "ğŸ—ï¸  Building application..."
npm run build

# Run AI Color Scheme Analysis (optional, non-blocking)
echo ""
echo "ğŸ¨ Running AI Color Scheme Analysis..."
if command -v ollama &> /dev/null && [ -f "scripts/ai-style-analyzer.js" ]; then
    echo "   This will analyze your components for styling consistency..."
    echo "   (Running in background, won't block startup)"
    
    # Run analyzer in background with timeout
    timeout 120 node scripts/ai-style-analyzer.js > ai-style-analysis.log 2>&1 &
    ANALYZER_PID=$!
    
    # Don't wait for it to complete
    echo "   Analysis started (PID: $ANALYZER_PID)"
    echo "   Check ai-style-analysis.log and ai-style-reports/ for results"
else
    echo "   âš ï¸  Skipping style analysis (Ollama or script not available)"
fi

# Restart the application
echo ""
echo "ğŸš€ Restarting application..."
npm start > server.log 2>&1 &

sleep 3

# Verify it's working
echo ""
if curl -s http://localhost:3000 > /dev/null; then
    echo "âœ… Update successful! Application is running on:"
    echo "   ğŸŒ http://localhost:3000"
    echo "   ğŸŒ http://$(hostname -I | awk '{print $1}'):3000"
    echo ""
    echo "ğŸ“‹ What was updated:"
    echo "   âœ… Application code from GitHub"
    echo "   âœ… Dependencies installed"
    echo "   âœ… libCEC support verified"
    echo "   âœ… Local AI (Ollama) verified"
    echo "   âœ… Database updated"
    echo "   âœ… AI style analysis running in background"
    echo ""
    echo "ğŸ¨ Style Analysis:"
    echo "   Check ai-style-reports/ for detailed component analysis"
    echo "   Run './scripts/run-style-analysis.sh' for interactive tools"
else
    echo "âŒ Update may have issues. Check server.log for details."
fi
