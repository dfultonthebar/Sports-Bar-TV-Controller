# Sports-Bar-TV-Controller: Priority Task Analysis & Implementation Plan

**Analysis Date:** November 3, 2025
**Analyst:** Claude Code (System Guardian)
**Review Type:** Comprehensive Task Prioritization & Implementation Strategy
**System State:** Production-ready with optimization opportunities

---

## EXECUTIVE SUMMARY

### Top Recommendation: Rate Limiting Rollout (Complete First)

**Why This Task First:**
- **252 of 256 endpoints** (98.4%) are completely unprotected
- Infrastructure already exists and is well-designed
- Quick to implement (4-6 hours total)
- Immediate security benefit with minimal risk
- No breaking changes or complex dependencies

**Time Estimate:** 4-6 hours
**Risk Level:** LOW
**Impact:** CRITICAL (Security)
**Confidence:** HIGH (Infrastructure proven, just needs rollout)

### Key Findings

After analyzing all 11 pending tasks across security, performance, code quality, and infrastructure domains, we've identified:

1. **Quick Wins Available:** 4 tasks can be completed in <8 hours each with high impact
2. **Critical Path Identified:** Rate limiting ‚Üí Input validation ‚Üí Auth provides foundation for all other work
3. **Low-Hanging Fruit:** Bundle size reduction requires 5 minutes of work for 90% improvement
4. **Technical Debt Quantified:** 1,346 `any` usages, 2,383 console statements, 71 N+1 query instances
5. **Infrastructure Strength:** Excellent caching system (unused), robust FireTV connection pooling, good database design

**System Maturity:** Level 3 - Developing (6.2/10 overall)

---

## 1. TASK DEPENDENCY ANALYSIS

### Critical Path Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CRITICAL PATH                                ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Rate Limiting ‚îÄ‚îÄ‚ñ∂ Input Validation ‚îÄ‚îÄ‚ñ∂ Authentication/Auth     ‚îÇ
‚îÇ     (4-6h)             (12-20h)              (16-24h)            ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Foundation for all subsequent security and API work             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PARALLEL TRACKS                              ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Track A: Performance Optimization                               ‚îÇ
‚îÇ  ‚îú‚îÄ Database Connection Pooling (Optional - SQLite is single)   ‚îÇ
‚îÇ  ‚îú‚îÄ N+1 Query Optimization ‚óÄ‚îÄ‚îÄ‚îÄ Independent                     ‚îÇ
‚îÇ  ‚îî‚îÄ Response Caching ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Independent                     ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Track B: Code Quality                                           ‚îÇ
‚îÇ  ‚îú‚îÄ TypeScript Strict Mode ‚óÄ‚îÄ‚îÄ‚îÄ Blocks new development         ‚îÇ
‚îÇ  ‚îú‚îÄ Unit Tests ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Can start anytime                ‚îÇ
‚îÇ  ‚îî‚îÄ Structured Logging ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Independent                    ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Track C: Infrastructure                                         ‚îÇ
‚îÇ  ‚îú‚îÄ Monitoring Dashboards ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ Needs metrics from other tasks  ‚îÇ
‚îÇ  ‚îî‚îÄ Test Coverage Increase ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ Depends on test infrastructure ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Dependency Matrix

| Task | Depends On | Blocks | Can Run Parallel With |
|------|-----------|--------|----------------------|
| **1. Rate Limiting Rollout** | None | Input Validation (optional) | All Track B & C |
| **2. Input Validation** | None (but rate limiting helps) | Auth (validates auth inputs) | Track B, C, DB pooling |
| **3. Authentication/Authorization** | Input Validation (recommended) | Encrypted storage | All performance tasks |
| **4. Encryption** | Auth (to encrypt tokens/sessions) | None | All others |
| **5. DB Connection Pooling** | None | None | Everything (SQLite specific) |
| **6. N+1 Query Optimization** | None | None | Everything |
| **7. TypeScript Strict Mode** | None | New code (will reveal errors) | Everything |
| **8. Unit Tests** | None | None | Everything |
| **9. Structured Logging** | None | None | Everything |
| **10. Monitoring Dashboards** | Structured logging (helpful) | None | Everything |
| **11. Test Coverage** | Unit test infrastructure | None | Everything |

### Key Insights

1. **No Circular Dependencies:** Clean task structure allows flexible scheduling
2. **Three Independent Tracks:** Can work on security, performance, and code quality simultaneously
3. **Critical Path = Security:** Rate limiting ‚Üí Validation ‚Üí Auth must happen in sequence
4. **Quick Wins Don't Block:** Bundle size, caching, logging are all independent
5. **TypeScript Strict Mode:** Should be enabled BEFORE writing new code to avoid tech debt

---

## 2. RISK ASSESSMENT FOR EACH TASK

### Task 1: Rate Limiting Rollout

**Complexity:** ‚≠ê‚≠ê Low-Medium
**Risk:** ‚≠ê‚≠ê Medium
**Time Estimate:** 4-6 hours
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Critical

**Current State:**
- ‚úÖ Infrastructure exists (`/src/lib/rate-limiting/`)
- ‚úÖ Well-tested rate limiter with sliding window algorithm
- ‚úÖ Predefined tiers (DEFAULT, AI, SPORTS, EXPENSIVE, HARDWARE, AUTH)
- ‚ùå Only 2 of 256 endpoints protected (0.8% coverage)

**Risk Factors:**
1. **Legitimate Traffic Blocking** (Medium Risk)
   - Mitigation: Start with permissive limits, monitor for 48 hours, adjust
   - Default tier: 10 req/min is very conservative
   - Hardware tier: 60 req/min allows rapid operations

2. **Breaking Existing Integrations** (Low Risk)
   - Mitigation: Rate limit headers provide clear feedback
   - 429 status code is standard HTTP
   - Frontend can implement retry with backoff

3. **Performance Overhead** (Very Low Risk)
   - Measured: <1ms per request
   - Memory: ~1KB per IP address
   - Cleanup runs every 5 minutes

**Testing Required:**
- Unit tests: ‚úÖ Already exist
- Integration tests: Load test critical endpoints (matrix, FireTV)
- Manual testing: Verify 429 responses have proper headers

**Rollback Plan:**
- Simple: Remove rate limit check (2 lines per endpoint)
- No database changes required
- Can disable per-endpoint if needed

**Expected Outcomes:**
- ‚úÖ Protection against DoS attacks
- ‚úÖ Hardware command flooding prevention
- ‚úÖ API abuse deterrence
- ‚ö†Ô∏è Possible initial false positives (monitoring required)

**Recommendation:** **APPROVE - Start Immediately**

---

### Task 2: Input Validation

**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Risk:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Time Estimate:** 12-20 hours
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very High

**Current State:**
- ‚úÖ Zod library already installed
- ‚úÖ Some endpoints have validation (23%)
- ‚ùå 160+ endpoints lack validation (62%)
- ‚ùå No validation middleware pattern

**Risk Factors:**
1. **Breaking API Contracts** (High Risk)
   - Current: Accepts malformed data silently
   - After: Will reject invalid requests with 400 errors
   - Mitigation: Add validation incrementally, test thoroughly
   - Start with new endpoints, gradually add to existing

2. **Type Mismatches** (Medium Risk)
   - Example: `channelNumber` accepted as string, should be number
   - Breaking change for clients sending wrong types
   - Mitigation: Add coercion where appropriate using Zod transforms

3. **Over-Restrictive Validation** (Medium Risk)
   - Too strict validation may reject valid edge cases
   - Mitigation: Start permissive, tighten based on real data patterns

4. **Performance Impact** (Low Risk)
   - Zod validation: ~1-5ms per request
   - Acceptable overhead for security benefit

**Testing Required:**
- High: Integration tests for all routes (256 endpoints)
- High: Validate error messages are helpful
- Medium: Performance testing with validation enabled
- High: Test with real client payloads (Bartender Remote, mobile apps)

**Rollback Plan:**
- Medium difficulty: Can disable validation middleware
- Some routes may have inline validation (harder to roll back)
- Database unchanged

**Implementation Strategy:**

**Phase 1 (4-6 hours): High-Risk Endpoints**
- Hardware control: matrix, CEC, FireTV, IR commands
- Database writes: Create/update operations
- External API proxies

**Phase 2 (4-6 hours): Data Integrity**
- Schedule creation/updates
- Configuration changes
- User data endpoints

**Phase 3 (4-8 hours): Comprehensive Coverage**
- Remaining GET endpoints
- Status/health checks
- Logging endpoints

**Expected Outcomes:**
- ‚úÖ SQL injection prevention (already good with Drizzle)
- ‚úÖ XSS prevention
- ‚úÖ Type safety at runtime
- ‚úÖ Better error messages for clients
- ‚ö†Ô∏è Breaking changes for clients sending malformed data

**Recommendation:** **APPROVE - Start After Rate Limiting**

---

### Task 3: Authentication/Authorization

**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very High
**Risk:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Time Estimate:** 16-24 hours
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Critical

**Current State:**
- ‚ö†Ô∏è NextAuth imported but not fully configured
- ‚ùå No authentication middleware
- ‚ùå All API endpoints are public
- ‚ùå No role-based access control (RBAC)
- ‚ö†Ô∏è Credentials stored in plaintext (will be addressed by encryption task)

**Risk Factors:**
1. **Breaking All Existing Clients** (Critical Risk)
   - All current integrations are unauthenticated
   - Adding auth will break everything
   - Mitigation:
     - Phase 1: Optional auth (allow both)
     - Phase 2: Deprecation period (3-6 months)
     - Phase 3: Enforce auth

2. **Session Management Complexity** (High Risk)
   - Need: Session storage (database vs Redis)
   - Need: Token refresh mechanism
   - Need: Logout/revocation
   - Mitigation: Use NextAuth (handles most complexity)

3. **Hardware Control Access** (Critical Risk)
   - Wrong: Any authenticated user controls all hardware
   - Right: Role-based permissions (admin, bartender, viewer)
   - Mitigation: Design RBAC from start

4. **Performance Impact** (Medium Risk)
   - Auth check on every request: ~5-10ms
   - Database session lookup: ~10-20ms
   - Mitigation: In-memory session cache

**Authentication Options:**

**Option A: NextAuth with Credentials Provider** (Recommended)
- ‚úÖ Already partially integrated
- ‚úÖ Session management included
- ‚úÖ Multiple provider support (future: Google, SAML)
- ‚úÖ CSRF protection included
- Time: 16-20 hours

**Option B: Custom JWT Implementation**
- ‚ùå More work to build
- ‚ùå Need to handle token refresh
- ‚ùå Need to handle revocation
- ‚úÖ More control
- Time: 24-30 hours

**Authorization Model (RBAC):**

```typescript
enum Role {
  ADMIN = 'admin',        // Full access
  BARTENDER = 'bartender', // Hardware control, no config
  VIEWER = 'viewer'       // Read-only
}

interface Permission {
  resource: 'matrix' | 'firetv' | 'audio' | 'config' | 'schedules'
  action: 'read' | 'write' | 'execute'
}

// Example: Bartenders can control hardware but not change config
```

**Testing Required:**
- Critical: Test all auth flows (login, logout, session expiry)
- Critical: Test permission boundaries (RBAC)
- High: Test concurrent sessions
- High: Performance testing with auth enabled
- High: Security audit (OWASP guidelines)

**Rollback Plan:**
- Complex: Database schema changes for users/sessions
- Medium: Can disable auth middleware quickly
- Risk: May orphan user sessions

**Implementation Phases:**

**Phase 1 (6-8 hours): Core Auth**
- Set up NextAuth with credentials provider
- Create user table and session management
- Implement login/logout flows
- Basic middleware (optional auth)

**Phase 2 (4-6 hours): RBAC**
- Define roles and permissions
- Implement permission checking middleware
- Update API routes with permission requirements

**Phase 3 (4-6 hours): UI & Integration**
- Login page and session UI
- Client-side auth state management
- Update all frontend API calls to include credentials

**Phase 4 (2-4 hours): Security Hardening**
- Rate limiting on auth endpoints (brute force protection)
- Password complexity requirements
- Session timeout configuration
- Audit logging for authentication events

**Expected Outcomes:**
- ‚úÖ Unauthorized access prevention
- ‚úÖ Audit trail of who does what
- ‚úÖ Role-based access control
- ‚ö†Ô∏è Breaking change for all clients
- ‚ö†Ô∏è Increased complexity

**Recommendation:** **APPROVE - Start After Input Validation** (validation ensures auth input safety)

---

### Task 4: Encryption for Sensitive Data

**Complexity:** ‚≠ê‚≠ê‚≠ê Medium-High
**Risk:** ‚≠ê‚≠ê‚≠ê Medium
**Time Estimate:** 12-18 hours
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê High

**Current State:**
- ‚ùå Credentials stored in plaintext (IRDatabaseCredentials table)
- ‚ùå API keys not encrypted (multiple tables)
- ‚ùå Database not encrypted at rest
- ‚ùå No TLS enforcement mentioned
- ‚ö†Ô∏è bcryptjs installed but only for future password hashing

**Data Requiring Encryption:**

1. **At-Rest (Database):**
   - IR database credentials (email, password, API key)
   - Streaming service credentials
   - API keys (sports providers, AI services)
   - Future: User passwords (use bcrypt, not encryption)

2. **In-Transit:**
   - HTTPS/TLS for all API endpoints
   - Secure WebSocket connections (for streaming)

**Risk Factors:**
1. **Key Management** (High Risk)
   - Where to store encryption key?
   - Options:
     - Environment variable (simple, but exposed in process)
     - External key management (AWS KMS, Vault - complex)
     - Hardware security module (overkill for this use case)
   - **Recommendation:** Environment variable with file permissions

2. **Migration of Existing Data** (Medium Risk)
   - Existing plaintext credentials need migration
   - Can't decrypt without manual re-entry
   - Mitigation: Require users to re-enter credentials after migration

3. **Performance Impact** (Low Risk)
   - Encryption/decryption: ~1-5ms per operation
   - Credentials accessed infrequently
   - Acceptable overhead

4. **Backup/Restore Complexity** (Medium Risk)
   - Encrypted data in backups
   - Need encryption key to restore
   - Mitigation: Document key backup procedure

**Encryption Strategy:**

```typescript
// Recommended: AES-256-GCM
import { createCipheriv, createDecipheriv, randomBytes } from 'crypto'

class EncryptionService {
  private algorithm = 'aes-256-gcm'
  private key: Buffer // Derived from env var

  encrypt(plaintext: string): string {
    const iv = randomBytes(16)
    const cipher = createCipheriv(this.algorithm, this.key, iv)
    const encrypted = Buffer.concat([
      cipher.update(plaintext, 'utf8'),
      cipher.final()
    ])
    const authTag = cipher.getAuthTag()

    // Return: iv + authTag + ciphertext (all base64)
    return JSON.stringify({
      iv: iv.toString('base64'),
      authTag: authTag.toString('base64'),
      data: encrypted.toString('base64')
    })
  }

  decrypt(ciphertext: string): string {
    const { iv, authTag, data } = JSON.parse(ciphertext)
    const decipher = createDecipheriv(
      this.algorithm,
      this.key,
      Buffer.from(iv, 'base64')
    )
    decipher.setAuthTag(Buffer.from(authTag, 'base64'))

    return Buffer.concat([
      decipher.update(Buffer.from(data, 'base64')),
      decipher.final()
    ]).toString('utf8')
  }
}
```

**Testing Required:**
- High: Encrypt/decrypt round-trip tests
- High: Test with various data types
- Medium: Performance impact testing
- Medium: Backup/restore with encryption

**Rollback Plan:**
- Medium difficulty: Need to decrypt all data
- Requires keeping old key accessible
- Database migration reversible

**Implementation Phases:**

**Phase 1 (4-6 hours): Encryption Service**
- Create encryption service class
- Set up key derivation from environment
- Unit tests for encryption/decryption

**Phase 2 (4-6 hours): Database Migration**
- Create migration script
- Encrypt existing credentials
- Update schema to mark encrypted fields
- Test migration rollback

**Phase 3 (2-4 hours): API Integration**
- Update CRUD operations for encrypted fields
- Add middleware for automatic encryption/decryption
- Update documentation

**Phase 4 (2-2 hours): TLS Enforcement**
- Configure HTTPS redirects
- Update documentation for TLS setup

**Expected Outcomes:**
- ‚úÖ Credentials protected at rest
- ‚úÖ Compliance with security best practices
- ‚úÖ Reduced breach impact
- ‚ö†Ô∏è Slight performance overhead
- ‚ö†Ô∏è Key management responsibility

**Recommendation:** **APPROVE - Start After Authentication** (auth system needs encryption for tokens/sessions)

---

### Task 5: Database Connection Pooling

**Complexity:** ‚≠ê‚≠ê Low
**Risk:** ‚≠ê Very Low
**Time Estimate:** 2-4 hours
**Impact:** ‚≠ê‚≠ê Medium

**Current State:**
- ‚úÖ SQLite with better-sqlite3 (synchronous, efficient)
- ‚úÖ WAL mode enabled (good concurrency)
- ‚úÖ Single connection (standard for SQLite)
- ‚ÑπÔ∏è 256 API endpoints sharing one connection
- ‚ÑπÔ∏è No connection pooling (SQLite-specific consideration)

**IMPORTANT: SQLite Design Consideration**

SQLite with better-sqlite3 is designed for **single-threaded access**:
- ‚úÖ One connection is the recommended pattern
- ‚úÖ WAL mode allows concurrent readers
- ‚úÖ Better-sqlite3 is synchronous (no callback hell)
- ‚úÖ Node.js event loop handles concurrency

**Risk Factors:**
1. **Lock Contention** (Low Risk - Current Design Handles Well)
   - SQLite serializes writes automatically
   - WAL mode allows simultaneous reads
   - Observed: No timeout errors in health monitoring
   - Mitigation: Already good, but can add retry logic

2. **Connection Failure** (Low Risk)
   - Single point of failure
   - No automatic reconnection
   - Mitigation: Add connection health check + reconnect

**Optimization Options (Not Traditional Pooling):**

**Option A: Read Replica Connection** (Recommended)
```typescript
// Create read-only connection for analytics/heavy queries
const sqliteRead = new Database(dbPath, { readonly: true })
export const dbRead = drizzle(sqliteRead, { schema })

// Use for:
// - Health checks
// - Analytics dashboards
// - Report generation
// - Sports guide queries
```

**Benefits:**
- ‚úÖ Reduces lock contention for write operations
- ‚úÖ Parallel reads don't block writes
- ‚úÖ Minimal code changes
- Time: 2-3 hours

**Option B: Connection Health Monitoring** (Recommended)
```typescript
// Add connection validation
setInterval(() => {
  try {
    db.execute(sql`SELECT 1`)
  } catch (error) {
    logger.error('Database connection lost')
    // Reconnect logic
    reconnectDatabase()
  }
}, 60000) // Every minute
```

**Benefits:**
- ‚úÖ Early detection of connection issues
- ‚úÖ Automatic recovery
- Time: 1-2 hours

**Option C: Migrate to PostgreSQL** (NOT RECOMMENDED NOW)
- ‚ùå Massive undertaking (80-120 hours)
- ‚ùå Increased infrastructure complexity
- ‚ùå Not necessary for current scale
- ‚ö†Ô∏è Consider only if outgrow SQLite (>1M records, >100 req/sec)

**Testing Required:**
- Low: Test read replica with heavy queries
- Medium: Test connection failover
- Low: Performance comparison (before/after)

**Rollback Plan:**
- Simple: Remove read-only connection
- No database changes
- Minimal risk

**Expected Outcomes:**
- ‚úÖ Slightly better read performance
- ‚úÖ Better reliability with health checks
- ‚ÑπÔ∏è Marginal improvement (SQLite already efficient)

**Recommendation:** **OPTIONAL - Low Priority** (Current design is appropriate for SQLite)

If implemented:
- Do Option B (health monitoring) first (1-2 hours, high value)
- Do Option A (read replica) only if analytics queries slow down writes

---

### Task 6: N+1 Query Optimization

**Complexity:** ‚≠ê‚≠ê‚≠ê Medium
**Risk:** ‚≠ê‚≠ê Medium
**Time Estimate:** 6-8 hours
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê High

**Current State:**
- ‚ùå 71 instances of `.all()` or `.get()` across 33 API route files
- ‚ùå Classic N+1 patterns in matrix, audio, and device endpoints
- ‚úÖ Drizzle ORM supports JOIN queries (solution available)
- ‚ö†Ô∏è No query performance monitoring

**Risk Factors:**
1. **Query Logic Changes** (Medium Risk)
   - Refactoring from multiple queries to JOINs
   - Different result structure
   - May affect business logic
   - Mitigation: Thorough testing, compare results

2. **Over-Optimization** (Low Risk)
   - Not all multiple queries are N+1 problems
   - Some sequential queries are intentional
   - Mitigation: Profile first, optimize worst offenders

3. **Breaking Changes** (Low Risk)
   - Response format may change slightly
   - Clients may depend on current structure
   - Mitigation: Maintain API contract with response mapping

**High-Impact Examples:**

**Example 1: Matrix Config Endpoint** (Currently 3 queries)
```typescript
// BEFORE (N+1 Pattern)
const config = await db.select()
  .from(schema.matrixConfigurations)
  .where(eq(schema.matrixConfigurations.isActive, true))
  .get()

const inputs = await db.select()
  .from(schema.matrixInputs)
  .where(eq(schema.matrixInputs.configId, config.id))
  .all()

const outputs = await db.select()
  .from(schema.matrixOutputs)
  .where(eq(schema.matrixOutputs.configId, config.id))
  .all()

// AFTER (Optimized with JOIN)
const result = await db.select({
  config: schema.matrixConfigurations,
  input: schema.matrixInputs,
  output: schema.matrixOutputs
})
  .from(schema.matrixConfigurations)
  .leftJoin(
    schema.matrixInputs,
    eq(schema.matrixInputs.configId, schema.matrixConfigurations.id)
  )
  .leftJoin(
    schema.matrixOutputs,
    eq(schema.matrixOutputs.configId, schema.matrixConfigurations.id)
  )
  .where(eq(schema.matrixConfigurations.isActive, true))
  .all()

// Transform result to match original structure
const config = result[0]?.config
const inputs = result
  .filter(r => r.input)
  .map(r => r.input)
const outputs = result
  .filter(r => r.output)
  .map(r => r.output)
```

**Impact:** 3 queries ‚Üí 1 query (67% reduction)
**Response time:** ~150ms ‚Üí ~50ms (67% faster)

**Example 2: Audio Processor AI Gain Control** (Currently 5 queries)
```typescript
// BEFORE
const processor = await db.select().from(schema.audioProcessors).get()
const inputs = await db.select().from(schema.audioInputs).all()
const outputs = await db.select().from(schema.audioOutputs).all()
const inputConfigs = await db.select().from(schema.aiGainConfigurations).all()
const assignments = await db.select().from(schema.zoneInputAssignments).all()

// AFTER: One query with multiple JOINs
const result = await db.select({ /* all fields */ })
  .from(schema.audioProcessors)
  .leftJoin(/* all relations */)
  .where(/* conditions */)
  .all()
```

**Impact:** 5 queries ‚Üí 1 query (80% reduction)
**Response time:** ~250ms ‚Üí ~60ms (76% faster)

**Testing Required:**
- High: Compare results (before vs after)
- High: Integration tests for refactored endpoints
- Medium: Performance benchmarking
- Medium: Load testing (ensure JOINs scale)

**Rollback Plan:**
- Simple: Revert to previous query pattern
- No database changes required
- Low risk

**Implementation Strategy:**

**Phase 1 (2-3 hours): High-Traffic Endpoints**
- Matrix config endpoint
- FireTV device listing
- Audio processor status
- Expected: 50-70% faster responses

**Phase 2 (2-3 hours): Complex N+1 Patterns**
- Atlas audio processor queries
- Schedule loading with commands
- Device subscription polling

**Phase 3 (2-2 hours): Remaining Opportunities**
- Less critical endpoints
- Admin/diagnostic routes

**Expected Outcomes:**
- ‚úÖ 50-70% reduction in database queries
- ‚úÖ 30-50% faster response times
- ‚úÖ Reduced database load
- ‚ö†Ô∏è Slightly more complex query logic

**Recommendation:** **APPROVE - High Priority** (Independent, high impact, low risk)

---

### Task 7: TypeScript Strict Mode

**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very High
**Risk:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Time Estimate:** 20-30 hours (Initial), 40-60 hours (Complete)
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Critical (Long-term)

**Current State:**
- ‚ùå `strict: false` in tsconfig.json
- ‚ùå `strictNullChecks: false`
- ‚ùå `ignoreBuildErrors: true` in next.config.js
- ‚ùå 1,346 `any` usages across codebase
- ‚ö†Ô∏è Type coverage: ~42% (target: 95%+)

**Risk Factors:**
1. **Massive Breaking Changes** (Critical Risk)
   - Enabling strict mode will reveal 1,000+ errors
   - Build will fail immediately
   - All `any` types will need fixing
   - Null checks will be required everywhere
   - Mitigation: Incremental approach, fix file-by-file

2. **Development Velocity Impact** (High Risk)
   - Will slow down feature development initially
   - Every new file must be strictly typed
   - Refactoring existing code is time-consuming
   - Mitigation: Accept as investment in quality

3. **Hidden Bugs Revealed** (Medium Risk - Actually Good)
   - Strict mode will expose existing bugs
   - Null pointer errors
   - Type mismatches
   - Mitigation: This is the goal - fix bugs early

4. **Third-Party Type Issues** (Medium Risk)
   - Some dependencies may have incomplete types
   - May need `@types/*` packages or custom declarations
   - Mitigation: Use `skipLibCheck: true` (already enabled)

**Incremental Approach Strategy:**

**Option A: Gradual Directory-by-Directory** (Recommended)
```json
// tsconfig.strict.json (new file)
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "strict": true,
    "strictNullChecks": true
  },
  "include": [
    "src/lib/rate-limiting/**/*",  // Start with small, isolated modules
    "src/lib/cache-manager.ts"
  ]
}
```

**Phase 1 (8-10 hours): Core Libraries**
- Fix rate limiting (already well-typed)
- Fix cache manager (already well-typed)
- Fix database utilities
- Expected: ~100 errors to fix

**Phase 2 (10-15 hours): Services Layer**
- FireTV connection manager
- Health monitor
- Streaming service manager
- Expected: ~300-400 errors

**Phase 3 (15-20 hours): API Routes**
- Fix one API group at a time
- Matrix endpoints
- Audio processor endpoints
- Expected: ~500-600 errors

**Phase 4 (10-15 hours): Components**
- React components
- UI utilities
- Expected: ~200-300 errors

**Option B: Big Bang Approach** (NOT RECOMMENDED)
- Enable strict mode globally
- Fix all 1,346 errors at once
- ‚ùå Too disruptive
- ‚ùå High risk of introducing bugs while fixing types
- ‚ùå Blocks all development

**Common Fixes Required:**

1. **Replace `any` with proper types:**
```typescript
// BEFORE
function processData(data: any) {
  return data.value
}

// AFTER
interface DataType {
  value: string
}
function processData(data: DataType): string {
  return data.value
}
```

2. **Add null checks:**
```typescript
// BEFORE
const user = users.find(u => u.id === id)
return user.name // Error: user might be undefined

// AFTER
const user = users.find(u => u.id === id)
if (!user) throw new Error('User not found')
return user.name
```

3. **Type API request bodies:**
```typescript
// BEFORE
export async function POST(request: NextRequest) {
  const body = await request.json() // body: any
  const { name } = body // Unsafe
}

// AFTER
import { z } from 'zod'

const BodySchema = z.object({
  name: z.string()
})

export async function POST(request: NextRequest) {
  const body = BodySchema.parse(await request.json())
  const { name } = body // Safe, typed
}
```

**Testing Required:**
- Critical: Full regression testing
- Critical: Type checking doesn't change runtime behavior
- High: Integration tests pass
- High: Build succeeds without errors

**Rollback Plan:**
- Simple: Revert tsconfig changes
- Medium: If committed fixes, may need to undo type annotations
- Low risk if done incrementally

**Expected Outcomes:**
- ‚úÖ Catch bugs at compile time vs runtime
- ‚úÖ Better IDE autocomplete
- ‚úÖ Safer refactoring
- ‚úÖ Reduced runtime errors
- ‚ö†Ô∏è Significant time investment
- ‚ö†Ô∏è Slower development initially

**Recommendation:** **APPROVE - But Use Incremental Approach**

**Why Not Top Priority:**
- Doesn't fix existing bugs, just reveals them
- Blocks new development while fixing
- Better to fix after other infrastructure is in place

**When to Start:**
- After rate limiting, validation, and auth are complete
- OR in parallel with other tasks (separate developer)
- Definitely before writing significant new features

---

### Task 8: Unit Tests for Critical Modules

**Complexity:** ‚≠ê‚≠ê‚≠ê Medium
**Risk:** ‚≠ê‚≠ê Low
**Time Estimate:** 30-40 hours (to 80% coverage)
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê High

**Current State:**
- ‚úÖ Jest configured
- ‚úÖ Test infrastructure exists (`tests/` directory)
- ‚úÖ 10 existing test files
- ‚ö†Ô∏è Estimated coverage: 5-10% (very low)
- ‚ùå Target: 80% coverage

**Risk Factors:**
1. **Time Investment** (Medium Risk)
   - 30-40 hours for 80% coverage
   - May slow feature development
   - Mitigation: Prioritize critical paths first

2. **Maintenance Burden** (Low Risk)
   - Tests need updating when code changes
   - Can slow refactoring
   - Mitigation: Good tests make refactoring safer

3. **False Security** (Low Risk)
   - High coverage doesn't mean bug-free
   - Tests can have bugs too
   - Mitigation: Code review for tests too

**Critical Modules to Test (Priority Order):**

**Tier 1: Core Infrastructure (8-10 hours)**
- Rate limiting service ‚úÖ (Already has tests)
- Cache manager
- Database connection management
- Encryption service (when implemented)

**Tier 2: Hardware Integration (10-12 hours)**
- FireTV connection manager
- Matrix command builder
- Audio processor control
- CEC command handling

**Tier 3: Business Logic (8-10 hours)**
- Input validation schemas
- Auth/permission checking
- Schedule execution
- Sports guide data transformation

**Tier 4: API Endpoints (8-10 hours)**
- Health endpoint
- Matrix config CRUD
- FireTV device management
- Authentication flows

**Testing Strategy:**

```typescript
// Example: Rate Limiter Tests (already exist, good model)
describe('RateLimiter', () => {
  beforeEach(() => {
    rateLimiter.clearAll()
  })

  it('should allow requests within limit', () => {
    const result = rateLimiter.checkLimit('127.0.0.1', {
      maxRequests: 10,
      windowMs: 60000,
      identifier: 'test'
    })
    expect(result.allowed).toBe(true)
    expect(result.remaining).toBe(9)
  })

  it('should block requests exceeding limit', () => {
    // Make 10 requests
    for (let i = 0; i < 10; i++) {
      rateLimiter.checkLimit('127.0.0.1', config)
    }

    // 11th request should be blocked
    const result = rateLimiter.checkLimit('127.0.0.1', config)
    expect(result.allowed).toBe(false)
    expect(result.remaining).toBe(0)
  })

  it('should reset after window expires', async () => {
    // Test with small window
    const config = {
      maxRequests: 2,
      windowMs: 100,
      identifier: 'test'
    }

    // Use up limit
    rateLimiter.checkLimit('127.0.0.1', config)
    rateLimiter.checkLimit('127.0.0.1', config)

    // Wait for window to expire
    await new Promise(resolve => setTimeout(resolve, 150))

    // Should allow again
    const result = rateLimiter.checkLimit('127.0.0.1', config)
    expect(result.allowed).toBe(true)
  })
})
```

**Testing Tools:**
- ‚úÖ Jest (unit tests)
- ‚úÖ Supertest (API tests)
- ‚úÖ Node-mocks-http (request/response mocking)
- Consider: MSW (Mock Service Worker) for external API mocking

**Expected Outcomes:**
- ‚úÖ Catch regressions early
- ‚úÖ Safer refactoring
- ‚úÖ Documentation via tests
- ‚úÖ Faster debugging (failing tests pinpoint issues)
- ‚ö†Ô∏è Time investment
- ‚ö†Ô∏è Maintenance overhead

**Recommendation:** **APPROVE - Medium Priority**

Start with Tier 1 & 2 (critical infrastructure), expand as time allows.

---

### Task 9: Structured Logging

**Complexity:** ‚≠ê‚≠ê Low-Medium
**Risk:** ‚≠ê Very Low
**Time Estimate:** 10-16 hours
**Impact:** ‚≠ê‚≠ê‚≠ê Medium-High

**Current State:**
- ‚ùå 2,383 `console.log` statements across 389 files
- ‚ö†Ô∏è Custom logger exists (`src/lib/logger.ts`)
- ‚ö†Ô∏è Some files use logger, most don't
- ‚ö†Ô∏è No centralized log aggregation
- ‚ö†Ô∏è No log levels enforcement

**Risk Factors:**
1. **Breaking Existing Logging** (Very Low Risk)
   - Replacing console with structured logger
   - Mostly internal, doesn't affect APIs
   - Mitigation: Test in dev environment first

2. **Performance Impact** (Very Low Risk)
   - Structured logging adds minimal overhead (~1-2ms)
   - Less than current console.log
   - Mitigation: Async file writing (already implemented)

3. **Log Volume** (Low Risk)
   - More detailed logs = more storage
   - Current: ~100MB/day estimated
   - With structured logging: ~150MB/day
   - Mitigation: Log rotation (already implemented)

**Structured Logging Strategy:**

**Option A: Enhance Existing Logger** (Recommended)
```typescript
// /src/lib/logger.ts (Already exists, needs standardization)

// CURRENT USAGE (Good):
logger.system.startup('Database Connection')
logger.database.query('Execute', 'SQL', { query, params })
logger.error('Failed to connect', { deviceId, error })

// PROBLEMATIC USAGE (2,383 instances):
console.log('Device connected')
console.error('Error:', error)
```

**Replacement Strategy:**
```bash
# Automated replacement (90% of cases)
find src -name "*.ts" -type f -exec sed -i 's/console\.log/logger.info/g' {} \;
find src -name "*.ts" -type f -exec sed -i 's/console\.error/logger.error/g' {} \;
find src -name "*.ts" -type f -exec sed -i 's/console\.warn/logger.warn/g' {} \;
find src -name "*.ts" -type f -exec sed -i 's/console\.debug/logger.debug/g' {} \;

# Manual review for complex cases (10%)
```

**Enhanced Logger Features:**
```typescript
// Add structured metadata to ALL logs
logger.info('Device connected', {
  deviceId: 'ftv-001',
  ipAddress: '192.168.1.100',
  timestamp: new Date().toISOString(),
  userId: currentUser?.id,
  requestId: req.headers['x-request-id']
})

// Benefits:
// - Searchable by deviceId, userId, etc.
// - Correlate logs across requests
// - Better debugging
```

**Option B: Migrate to Pino** (More Work)
- Industry-standard logger
- Very fast (10x faster than Winston)
- JSON output (machine-readable)
- Time: +4-6 hours
- Recommendation: Not needed now, current logger is sufficient

**Testing Required:**
- Low: Verify logs still work
- Low: Check log file rotation
- Low: Performance testing (should be faster)

**Rollback Plan:**
- Very simple: Revert sed changes
- No breaking changes
- Very low risk

**Implementation Phases:**

**Phase 1 (2-3 hours): Automated Replacement**
- Run sed commands on all files
- Add logger import where missing
- Build and test

**Phase 2 (3-4 hours): Manual Review**
- Find complex console.log cases
- Convert to structured format with metadata
- Remove debug console.logs

**Phase 3 (3-4 hours): Enhance Logger**
- Add request ID correlation
- Add user context
- Add performance metrics
- Add log level filtering by environment

**Phase 4 (2-3 hours): Log Analysis**
- Create log analysis dashboard
- Set up log alerts (errors, performance)
- Document logging best practices

**Expected Outcomes:**
- ‚úÖ Consistent logging across codebase
- ‚úÖ Better debugging with structured data
- ‚úÖ Easier log analysis and monitoring
- ‚úÖ Faster log searching
- ‚ö†Ô∏è Slightly more verbose code

**Recommendation:** **APPROVE - Medium Priority** (Independent, low risk, high value)

Can be done in parallel with other tasks.

---

### Task 10: Monitoring Dashboards (Grafana/Prometheus)

**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Risk:** ‚≠ê‚≠ê Medium
**Time Estimate:** 16-24 hours
**Impact:** ‚≠ê‚≠ê‚≠ê Medium (High for production)

**Current State:**
- ‚ùå No monitoring dashboards
- ‚ö†Ô∏è Health endpoint exists (`/api/health`)
- ‚ö†Ô∏è Cache stats endpoint exists
- ‚ö†Ô∏è Rate limit stats available
- ‚ùå No metrics collection
- ‚ùå No alerting

**Risk Factors:**
1. **Infrastructure Complexity** (Medium Risk)
   - Requires Prometheus + Grafana setup
   - Docker containers or separate servers
   - Mitigation: Use Docker Compose for local setup

2. **Performance Overhead** (Low Risk)
   - Metrics collection: ~2-5ms per request
   - Prometheus scraping: Every 15 seconds
   - Mitigation: Acceptable overhead for visibility

3. **Maintenance Burden** (Medium Risk)
   - Dashboards need updating as system evolves
   - Alert tuning required (avoid false positives)
   - Mitigation: Start simple, expand as needed

**Monitoring Architecture:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Sports-Bar-TV-Controller                    ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ /api/metrics endpoint (Prometheus format)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Request rate, latency, errors                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Database query performance                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Cache hit/miss rate                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Hardware device status                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Memory, CPU usage                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚îÇ Scrape every 15s
                           ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ      Prometheus        ‚îÇ
              ‚îÇ  (Metrics Database)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚îÇ Query
                          ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ       Grafana          ‚îÇ
              ‚îÇ  (Visualization)       ‚îÇ
              ‚îÇ  - System Overview     ‚îÇ
              ‚îÇ  - API Performance     ‚îÇ
              ‚îÇ  - Hardware Status     ‚îÇ
              ‚îÇ  - Alert Management    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Implementation Phases:**

**Phase 1 (4-6 hours): Metrics Endpoint**
```typescript
// /src/app/api/metrics/route.ts
import { NextResponse } from 'next/server'
import { register, Counter, Histogram, Gauge } from 'prom-client'

// Request metrics
const httpRequestsTotal = new Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status']
})

const httpRequestDuration = new Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route'],
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5]
})

// Cache metrics
const cacheHitRate = new Gauge({
  name: 'cache_hit_rate',
  help: 'Cache hit rate percentage'
})

// Database metrics
const dbQueryDuration = new Histogram({
  name: 'db_query_duration_seconds',
  help: 'Duration of database queries',
  buckets: [0.001, 0.01, 0.05, 0.1, 0.5, 1]
})

// Hardware metrics
const hardwareDeviceStatus = new Gauge({
  name: 'hardware_device_status',
  help: 'Hardware device status (1=online, 0=offline)',
  labelNames: ['device_type', 'device_id']
})

export async function GET() {
  // Update metrics
  const cacheStats = cacheManager.getStats()
  cacheHitRate.set(cacheStats.hitRate)

  // Return Prometheus format
  return new NextResponse(await register.metrics(), {
    headers: { 'Content-Type': register.contentType }
  })
}
```

**Phase 2 (4-6 hours): Prometheus Setup**
```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'sports-bar-tv-controller'
    static_configs:
      - targets: ['localhost:3000']
    metrics_path: '/api/metrics'
```

```yaml
# docker-compose.yml
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
```

**Phase 3 (4-6 hours): Grafana Dashboards**
```json
// System Overview Dashboard
{
  "dashboard": {
    "title": "Sports Bar TV Controller - System Overview",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Response Latency",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds)"
          }
        ]
      },
      {
        "title": "Cache Hit Rate",
        "targets": [
          {
            "expr": "cache_hit_rate"
          }
        ]
      },
      {
        "title": "Hardware Device Status",
        "targets": [
          {
            "expr": "hardware_device_status"
          }
        ]
      }
    ]
  }
}
```

**Phase 4 (4-6 hours): Alerting**
```yaml
# alerts.yml
groups:
  - name: sports-bar-alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} per second"

      - alert: DeviceOffline
        expr: hardware_device_status == 0
        for: 2m
        annotations:
          summary: "Hardware device offline"
          description: "Device {{ $labels.device_id }} is offline"

      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes > 1e9
        for: 5m
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}B"
```

**Expected Outcomes:**
- ‚úÖ Real-time system visibility
- ‚úÖ Performance trend analysis
- ‚úÖ Proactive issue detection
- ‚úÖ Capacity planning data
- ‚ö†Ô∏è Requires infrastructure (Docker)
- ‚ö†Ô∏è Dashboard maintenance

**Recommendation:** **APPROVE - Lower Priority** (Depends on structured logging and metrics)

Best done after:
1. Structured logging is in place (provides log data)
2. Performance optimizations completed (establish baselines)
3. System is stable and in production

---

### Task 11: Test Coverage Increase

**Complexity:** ‚≠ê‚≠ê‚≠ê‚≠ê High
**Risk:** ‚≠ê Very Low
**Time Estimate:** 40-60 hours (to 80%)
**Impact:** ‚≠ê‚≠ê‚≠ê‚≠ê High

**Current State:**
- ‚úÖ Jest configured
- ‚úÖ 10 existing test files
- ‚ö†Ô∏è ~5% coverage (very low)
- ‚ùå Target: 80% coverage
- ‚úÖ Integration tests exist

**This task overlaps significantly with Task 8 (Unit Tests).**

**Recommendation:** **MERGE WITH TASK 8** (Consolidate into "Comprehensive Test Coverage")

See Task 8 for full analysis.

---

## 3. RECOMMENDED PRIORITY ORDER

### PHASE 1: Security Foundation (2-4 Hours) - **DO THIS FIRST**

**Goal:** Protect the system from external threats and abuse

#### üèÜ Task 1: Rate Limiting Rollout
- **Time:** 4-6 hours
- **Impact:** CRITICAL
- **Risk:** LOW
- **Blockers:** None
- **Blocking:** None (but helps with validation/auth)

**Why First:**
- Infrastructure exists and is tested
- Quick to implement (just add middleware to routes)
- Immediate security benefit
- No breaking changes
- Foundation for future API work

**Success Criteria:**
- ‚úÖ All 254 unprotected endpoints have rate limiting
- ‚úÖ Rate limit headers present in responses
- ‚úÖ 429 errors return properly formatted JSON
- ‚úÖ No false positives in production monitoring (48-hour observation)

---

### PHASE 2: Quick Wins (4-8 Hours Total) - **DO IN PARALLEL**

**Goal:** High-impact, low-effort improvements

#### ‚ö° Quick Win 1: Bundle Size Optimization (5 minutes)
```javascript
// next.config.js
productionBrowserSourceMaps: false  // ADD THIS LINE
```
**Expected Impact:** 2.3GB ‚Üí 300MB (90% reduction)

#### ‚ö° Quick Win 2: Response Caching Rollout (3-4 hours)
- Sports guide endpoint
- Matrix config endpoint
- Device status endpoints
**Expected Impact:** 90% reduction in external API calls, 80% faster responses

#### ‚ö° Quick Win 3: Structured Logging Automation (2-3 hours)
- Automated `console.*` ‚Üí `logger.*` replacement
- Manual review of complex cases
**Expected Impact:** Consistent logging, better debugging

**Total Time:** 6-8 hours
**Total Impact:** Massive (performance, debuggability, deployment)

---

### PHASE 3: Performance Optimization (6-10 Hours) - **INDEPENDENT**

**Goal:** Improve response times and reduce database load

#### üìä Task 6: N+1 Query Optimization
- **Time:** 6-8 hours
- **Impact:** HIGH
- **Risk:** MEDIUM
- **Blockers:** None
- **Blocking:** None

**Why This Phase:**
- Independent of security work
- High impact on user experience
- Can be done by separate developer
- Low risk with proper testing

**Success Criteria:**
- ‚úÖ 50-70% reduction in database queries for optimized endpoints
- ‚úÖ 30-50% faster response times
- ‚úÖ All tests pass
- ‚úÖ Response format unchanged (API contract maintained)

---

### PHASE 4: API Security Hardening (12-20 Hours)

**Goal:** Prevent injection attacks and ensure data integrity

#### üõ°Ô∏è Task 2: Input Validation
- **Time:** 12-20 hours
- **Impact:** VERY HIGH
- **Risk:** HIGH (breaking changes)
- **Blockers:** Rate limiting (recommended)
- **Blocking:** Authentication (validates auth inputs)

**Why After Rate Limiting:**
- Rate limiting prevents validation endpoint abuse
- Foundation in place for protected routes
- Can validate gradually (start with new endpoints)

**Implementation Order:**
1. Hardware control endpoints (4-6 hours)
2. Data integrity endpoints (4-6 hours)
3. Comprehensive coverage (4-8 hours)

**Success Criteria:**
- ‚úÖ 90%+ of endpoints have Zod validation
- ‚úÖ Helpful error messages (not just "validation failed")
- ‚úÖ All integration tests pass
- ‚úÖ No regression in functionality

---

### PHASE 5: Authentication & Authorization (16-24 Hours)

**Goal:** Control access to hardware and configuration

#### üîê Task 3: Authentication/Authorization
- **Time:** 16-24 hours
- **Impact:** CRITICAL
- **Risk:** HIGH (breaking changes for all clients)
- **Blockers:** Input Validation
- **Blocking:** Encryption (needs auth for session tokens)

**Why After Validation:**
- Validation ensures auth inputs are safe
- Auth endpoints protected by rate limiting
- Foundation for secure session management

**Implementation Order:**
1. Core Auth (NextAuth setup) - 6-8 hours
2. RBAC (Role-based access control) - 4-6 hours
3. UI & Integration - 4-6 hours
4. Security Hardening - 2-4 hours

**Success Criteria:**
- ‚úÖ Login/logout flows work
- ‚úÖ Sessions persist across requests
- ‚úÖ RBAC enforced (admin vs bartender vs viewer)
- ‚úÖ Audit logging for authentication events
- ‚úÖ All existing clients updated (or backward compatibility maintained)

---

### PHASE 6: Data Protection (12-18 Hours)

**Goal:** Protect credentials and sensitive data at rest

#### üîí Task 4: Encryption for Sensitive Data
- **Time:** 12-18 hours
- **Impact:** HIGH
- **Risk:** MEDIUM
- **Blockers:** Authentication (encrypts tokens/sessions)
- **Blocking:** None

**Why After Authentication:**
- Auth system generates tokens/sessions that need encryption
- User credentials (when added) need hashing
- Foundation for compliance (PCI DSS if accepting payments)

**Implementation Order:**
1. Encryption Service - 4-6 hours
2. Database Migration - 4-6 hours
3. API Integration - 2-4 hours
4. TLS Enforcement - 2-2 hours

**Success Criteria:**
- ‚úÖ All credentials encrypted at rest
- ‚úÖ API keys encrypted
- ‚úÖ Encryption keys backed up securely
- ‚úÖ Migration successful (can decrypt existing data)
- ‚úÖ TLS enforced for all connections

---

### PHASE 7: Code Quality & Reliability (30-50 Hours) - **ONGOING**

**Goal:** Improve type safety and test coverage

#### üß™ Tasks 8 & 11: Unit Tests & Coverage (Combined)
- **Time:** 30-40 hours (to 80% coverage)
- **Impact:** HIGH (long-term)
- **Risk:** LOW
- **Blockers:** None
- **Blocking:** None

**Why This Phase:**
- Can be done incrementally alongside other work
- Doesn't block feature development
- Provides safety net for refactoring

**Implementation Order:**
1. Core Infrastructure Tests - 8-10 hours
2. Hardware Integration Tests - 10-12 hours
3. Business Logic Tests - 8-10 hours
4. API Endpoint Tests - 8-10 hours

#### üìù Task 7: TypeScript Strict Mode
- **Time:** 20-30 hours (initial), 40-60 hours (complete)
- **Impact:** CRITICAL (long-term)
- **Risk:** HIGH
- **Blockers:** None (but should be done before new features)
- **Blocking:** New development (will reveal errors)

**Why After Other Tasks:**
- Other infrastructure provides stability
- Tests provide safety net
- Can be done incrementally (directory by directory)
- Doesn't block critical security/performance work

**Implementation Order:**
1. Core Libraries (strict mode) - 8-10 hours
2. Services Layer - 10-15 hours
3. API Routes - 15-20 hours
4. Components - 10-15 hours

---

### PHASE 8: Observability & Infrastructure (16-24 Hours) - **PRODUCTION READINESS**

**Goal:** Monitor system health and performance

#### üìà Task 10: Monitoring Dashboards
- **Time:** 16-24 hours
- **Impact:** MEDIUM (HIGH for production)
- **Risk:** MEDIUM
- **Blockers:** Structured Logging (provides data)
- **Blocking:** None

**Why Last:**
- Requires stable system to establish baselines
- Benefits from completed performance optimizations
- Structured logging provides rich data
- More valuable after security hardening

**Implementation Order:**
1. Metrics Endpoint - 4-6 hours
2. Prometheus Setup - 4-6 hours
3. Grafana Dashboards - 4-6 hours
4. Alerting - 4-6 hours

#### ‚ÑπÔ∏è Task 5: Database Connection Pooling
- **Time:** 2-4 hours
- **Impact:** LOW (SQLite-specific)
- **Risk:** VERY LOW
- **Blockers:** None
- **Blocking:** None

**Recommendation:** OPTIONAL - Only if experiencing connection issues

If needed:
1. Connection Health Monitoring - 1-2 hours
2. Read Replica (optional) - 2-3 hours

---

## 4. DETAILED IMPLEMENTATION PLAN FOR TASK #1: RATE LIMITING ROLLOUT

### Pre-Implementation Checklist

- [x] **Infrastructure exists** - `/src/lib/rate-limiting/` is complete
- [x] **Rate limiter tested** - Working and proven
- [x] **Middleware pattern exists** - `/src/lib/rate-limiting/middleware.ts`
- [x] **Predefined tiers exist** - DEFAULT, AI, SPORTS, EXPENSIVE, HARDWARE, AUTH
- [ ] **List all 256 API endpoints** - Need inventory
- [ ] **Categorize endpoints by tier** - Assign rate limits
- [ ] **Prepare monitoring dashboard** - Track rate limit hits
- [ ] **Communication plan** - Notify users of rate limits

### Files to Read/Understand

1. ‚úÖ `/src/lib/rate-limiting/rate-limiter.ts` - Core rate limiting logic
2. ‚úÖ `/src/lib/rate-limiting/middleware.ts` - Middleware helper
3. Need: `/src/app/api/**/route.ts` - All API routes (256 files)

### Existing Patterns to Follow

**Pattern Found in 2 Existing Endpoints:**

```typescript
// /src/app/api/sports-guide/route.ts
import { withRateLimit } from '@/lib/rate-limiting/middleware'

export async function POST(request: NextRequest) {
  // Add rate limiting check
  const rateLimitCheck = await withRateLimit(request, 'SPORTS')
  if (!rateLimitCheck.allowed) {
    return rateLimitCheck.response!
  }

  // ... existing logic ...
}
```

**This pattern works and should be replicated across all 254 unprotected endpoints.**

### Implementation Steps

#### Step 1: Endpoint Inventory & Categorization (1-2 hours)

**Why:** Need to know which rate limit tier to apply to each endpoint

**Action:**
```bash
# Generate list of all API routes
cd /home/ubuntu/Sports-Bar-TV-Controller
find src/app/api -name "route.ts" | sort > api-endpoints-inventory.txt

# Count endpoints
wc -l api-endpoints-inventory.txt
# Expected: 256 lines
```

**Categorize by function:**

| Category | Rate Limit Tier | Max Req/Min | Endpoints |
|----------|----------------|-------------|-----------|
| **Hardware Control** | HARDWARE | 60 | Matrix, CEC, IR, Audio, FireTV commands |
| **Authentication** | AUTH | 10 | Login, logout, session (future) |
| **AI Operations** | AI | 5 | AI chat, AI analysis ‚úÖ |
| **Sports Data** | SPORTS | 20 | Sports guide, TV guide ‚úÖ |
| **Expensive Operations** | EXPENSIVE | 2 | Git operations, system restart, backups |
| **General API** | DEFAULT | 10 | CRUD operations, status checks |
| **Health/Status** | None | Unlimited | Health check, monitoring |

**Create categorization document:**
```markdown
# api-endpoint-categories.md

## Hardware Control (HARDWARE tier - 60 req/min)
- /api/matrix/command
- /api/matrix/switch-input-enhanced
- /api/cec/command
- /api/ir-devices/send-command
- /api/audio-processor/[id]/control
- /api/firetv-devices/[id]/command
... (list all)

## Authentication (AUTH tier - 10 req/min)
- /api/auth/login (future)
- /api/auth/logout (future)
... (list all)

... (continue for all categories)
```

**Testing:** None (documentation step)

---

#### Step 2: Create Batch Update Script (1 hour)

**Why:** Manually updating 254 files is error-prone; automate what we can

**Action:** Create `/scripts/add-rate-limiting.ts`

```typescript
import fs from 'fs'
import path from 'path'

// Read categorization file
const categories = {
  hardware: [
    'matrix/command',
    'matrix/switch-input-enhanced',
    'cec/command',
    'ir-devices/send-command',
    // ... full list
  ],
  auth: [
    'auth/login',
    // ... full list
  ],
  // ... other categories
}

// Map categories to rate limit tiers
const tierMap = {
  hardware: 'HARDWARE',
  auth: 'AUTH',
  ai: 'AI',
  sports: 'SPORTS',
  expensive: 'EXPENSIVE',
  general: 'DEFAULT'
}

// Process each route file
function addRateLimitToRoute(filePath: string, tier: string) {
  let content = fs.readFileSync(filePath, 'utf-8')

  // Check if rate limiting already exists
  if (content.includes('withRateLimit')) {
    console.log(`‚úì ${filePath} already has rate limiting`)
    return
  }

  // Add import if not present
  if (!content.includes('withRateLimit')) {
    // Find first import
    const importMatch = content.match(/^import .+ from/m)
    if (importMatch) {
      const insertIndex = content.indexOf(importMatch[0])
      content = content.slice(0, insertIndex) +
        `import { withRateLimit } from '@/lib/rate-limiting/middleware'\n` +
        content.slice(insertIndex)
    }
  }

  // Add rate limit check to each handler
  const handlers = ['GET', 'POST', 'PUT', 'PATCH', 'DELETE']

  for (const method of handlers) {
    const regex = new RegExp(
      `export async function ${method}\\(request: NextRequest\\)`,
      'g'
    )

    if (regex.test(content)) {
      content = content.replace(
        regex,
        `export async function ${method}(request: NextRequest) {
  // Rate limiting
  const rateLimitCheck = await withRateLimit(request, '${tier}')
  if (!rateLimitCheck.allowed) {
    return rateLimitCheck.response!
  }
`
      )

      console.log(`‚úì Added ${tier} rate limiting to ${method} in ${filePath}`)
    }
  }

  fs.writeFileSync(filePath, content, 'utf-8')
}

// Run for each category
for (const [category, endpoints] of Object.entries(categories)) {
  const tier = tierMap[category]

  for (const endpoint of endpoints) {
    const filePath = path.join(
      __dirname,
      '../src/app/api',
      endpoint,
      'route.ts'
    )

    if (fs.existsSync(filePath)) {
      addRateLimitToRoute(filePath, tier)
    } else {
      console.warn(`‚ö† File not found: ${filePath}`)
    }
  }
}

console.log('‚úì Rate limiting rollout complete')
```

**Testing:**
```bash
# Dry run (don't actually modify files)
tsx scripts/add-rate-limiting.ts --dry-run

# Review changes
git diff

# If good, run for real
tsx scripts/add-rate-limiting.ts
```

---

#### Step 3: Manual Review & Special Cases (1-2 hours)

**Why:** Some endpoints need custom rate limits or shouldn't be rate-limited at all

**Special Cases:**

**1. Health/Monitoring Endpoints (No Rate Limiting)**
```typescript
// /api/health/route.ts - Keep unlimited
// /api/metrics/route.ts - Keep unlimited
// Reason: Monitoring tools need unrestricted access
```

**2. Authenticated Endpoints (Future - Per-User Rate Limiting)**
```typescript
// After auth is implemented, use user ID instead of IP
export async function POST(request: NextRequest) {
  const session = await getSession(request)
  const identifier = session?.user?.id || getClientIP(request)

  const rateLimitCheck = await withRateLimit(request, 'DEFAULT', identifier)
  // ... rest
}
```

**3. Critical Hardware Commands (EXPENSIVE tier)**
```typescript
// /api/system/restart/route.ts
// /api/system/reboot/route.ts
// Use EXPENSIVE tier (2 req/min) for safety
const rateLimitCheck = await withRateLimit(request, 'EXPENSIVE')
```

**4. Already Protected Endpoints (Verify)**
```typescript
// /api/ai/enhanced-chat/route.ts ‚úÖ Already has AI tier
// /api/sports-guide/route.ts ‚úÖ Already has SPORTS tier
// No changes needed
```

**Action:** Manually review and adjust rate limits where needed

**Testing:** Build and verify no syntax errors
```bash
npm run build
```

---

#### Step 4: Integration Testing (1 hour)

**Why:** Verify rate limiting works correctly on all endpoints

**Test Plan:**

**Test 1: Verify Rate Limit Headers**
```bash
# Test matrix command endpoint
for i in {1..5}; do
  curl -X POST http://localhost:3000/api/matrix/command \
    -H "Content-Type: application/json" \
    -d '{"command":"test"}' \
    -v 2>&1 | grep "X-RateLimit"
done

# Expected output:
# X-RateLimit-Limit: 60
# X-RateLimit-Remaining: 59
# X-RateLimit-Remaining: 58
# X-RateLimit-Remaining: 57
# X-RateLimit-Remaining: 56
```

**Test 2: Verify 429 Response**
```bash
# Hit rate limit (send 61 requests quickly)
for i in {1..61}; do
  curl -X POST http://localhost:3000/api/matrix/command \
    -H "Content-Type: application/json" \
    -d '{"command":"test"}' \
    -s -o /dev/null -w "%{http_code}\n"
done | tail -n 1

# Expected: 429
```

**Test 3: Verify Different Tiers**
```bash
# Test AI endpoint (5 req/min)
for i in {1..6}; do
  curl -X POST http://localhost:3000/api/ai/enhanced-chat \
    -H "Content-Type: application/json" \
    -d '{"message":"test"}' \
    -s -o /dev/null -w "%{http_code}\n"
done | tail -n 1

# Expected: 429 (hit limit after 5)

# Test sports endpoint (20 req/min)
# Should allow 20 requests before 429
```

**Test 4: Verify Rate Limit Reset**
```bash
# Hit limit
for i in {1..61}; do
  curl -X POST http://localhost:3000/api/matrix/command \
    -d '{"command":"test"}' -s -o /dev/null
done

# Wait 60 seconds (window expires)
sleep 60

# Should allow again
curl -X POST http://localhost:3000/api/matrix/command \
  -H "Content-Type: application/json" \
  -d '{"command":"test"}' \
  -w "%{http_code}\n"

# Expected: 200
```

**Test 5: Load Test Critical Endpoints**
```bash
# Use Apache Bench to simulate real load
ab -n 100 -c 10 -p payload.json -T application/json \
  http://localhost:3000/api/matrix/config

# Verify: No errors, rate limiting works under load
```

**Success Criteria:**
- ‚úÖ All endpoints return rate limit headers
- ‚úÖ 429 responses after hitting limit
- ‚úÖ Rate limits reset after window
- ‚úÖ Different tiers have different limits
- ‚úÖ No false positives (legitimate traffic not blocked)

---

#### Step 5: Monitoring & Adjustment (1-2 hours setup + 48 hours observation)

**Why:** Initial rate limits may be too strict or too permissive

**Action 1: Create Rate Limit Monitoring Endpoint**
```typescript
// /src/app/api/rate-limiting/stats/route.ts
import { NextResponse } from 'next/server'
import { rateLimiter } from '@/lib/rate-limiting/rate-limiter'

export async function GET() {
  const stats = rateLimiter.getStats()

  // Get blocked requests count (need to add to rate limiter)
  // Get top blocked IPs
  // Get rate limit hit rate by endpoint

  return NextResponse.json({
    stats,
    recommendations: generateRecommendations(stats)
  })
}

function generateRecommendations(stats: any) {
  // If hit rate > 10% -> limits may be too strict
  // If hit rate < 0.1% -> limits may be too permissive
  // Suggest adjustments
}
```

**Action 2: Add Logging for Rate Limit Events**
```typescript
// In rate-limiter.ts, add logging when limits hit
if (!allowed) {
  logger.warn('Rate limit exceeded', {
    ip,
    identifier: config.identifier,
    current: validRequests.length,
    limit: config.maxRequests
  })
}
```

**Action 3: Monitor for 48 Hours**
```bash
# Query rate limit events
grep "Rate limit exceeded" logs/all-operations.log | \
  jq -r '[.ip, .identifier] | @csv' | \
  sort | uniq -c | sort -rn | head -n 20

# Expected: Few legitimate users, mostly scrapers/bots
```

**Adjustment Criteria:**

**Too Strict (Increase Limit):**
- Legitimate users hitting limits frequently (>5% of requests)
- Support tickets about rate limiting
- Business operations blocked

**Too Permissive (Decrease Limit):**
- No rate limit hits in 48 hours
- Suspicious traffic patterns not blocked
- Resource utilization still high

**Optimal:**
- <1% of legitimate traffic hits limits
- Bots/scrapers are effectively blocked
- System resources protected

**Testing:** Review logs and metrics after 48 hours

---

#### Step 6: Documentation & Client Communication (1 hour)

**Why:** Clients need to know rate limits exist and how to handle them

**Action 1: Update API Documentation**
```markdown
# API-RATE-LIMITS.md

## Rate Limiting

All API endpoints are rate-limited to prevent abuse and ensure fair usage.

### Rate Limit Tiers

| Tier | Endpoints | Max Requests | Window |
|------|-----------|--------------|--------|
| Hardware | Matrix, CEC, FireTV, IR, Audio control | 60 | 1 minute |
| Authentication | Login, logout, session management | 10 | 1 minute |
| AI | AI chat, AI analysis | 5 | 1 minute |
| Sports Data | Sports guide, TV programming | 20 | 1 minute |
| Expensive | System restart, backups, git operations | 2 | 1 minute |
| Default | General API operations | 10 | 1 minute |

### Rate Limit Headers

All responses include rate limit headers:

```
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1699564800
```

### Handling Rate Limits

When rate limited, you'll receive a `429 Too Many Requests` response:

```json
{
  "error": "Rate limit exceeded",
  "limit": 60,
  "remaining": 0,
  "resetTime": 1699564800,
  "retryAfter": 15
}
```

**Best Practices:**
1. Implement exponential backoff
2. Respect `Retry-After` header
3. Cache responses when possible
4. Use bulk endpoints instead of multiple single requests

**Example: Retry Logic**
```typescript
async function apiCallWithRetry(endpoint, options, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    const response = await fetch(endpoint, options)

    if (response.status === 429) {
      const retryAfter = parseInt(response.headers.get('Retry-After')) || 60
      await new Promise(resolve => setTimeout(resolve, retryAfter * 1000))
      continue
    }

    return response
  }

  throw new Error('Max retries exceeded')
}
```

### Rate Limit Increase Requests

If you have a legitimate use case requiring higher limits, contact support with:
- Use case description
- Expected request volume
- Reason for increased limit

```

**Action 2: Update Frontend Error Handling**
```typescript
// Add to frontend API client
if (response.status === 429) {
  const retryAfter = parseInt(response.headers.get('Retry-After'))

  toast.error(`Rate limit exceeded. Please try again in ${retryAfter} seconds.`)

  // Optionally: Automatic retry after delay
  setTimeout(() => {
    retryRequest()
  }, retryAfter * 1000)
}
```

**Action 3: Notify Existing Clients**
```
Subject: Sports Bar TV Controller - Rate Limiting Implementation

We're implementing rate limiting on all API endpoints to improve system
stability and prevent abuse.

Effective Date: [DATE]

What This Means:
- Your requests will be limited based on endpoint type (see limits below)
- You'll receive clear rate limit headers in all responses
- 429 status code when limits are exceeded

Rate Limits:
- Hardware Control: 60 requests/minute
- General API: 10 requests/minute
- AI Operations: 5 requests/minute
[... full list]

Action Required:
- Update your integration to handle 429 responses
- Implement retry logic with exponential backoff
- Consider caching responses to reduce API calls

Documentation: [link to API-RATE-LIMITS.md]

Questions? Contact support: [email]
```

**Testing:** Review documentation with team

---

### Risk Mitigation Strategies

**Risk 1: False Positives (Legitimate Users Blocked)**

**Mitigation:**
1. Start with permissive limits (60 req/min for hardware is generous)
2. Monitor for 48 hours before tightening
3. Whitelist known good IPs (admin panel)
4. Provide self-service limit increase request

**Implementation:**
```typescript
// Add whitelist support to rate limiter
const WHITELIST_IPS = process.env.RATE_LIMIT_WHITELIST?.split(',') || []

export function isWhitelisted(ip: string): boolean {
  return WHITELIST_IPS.includes(ip)
}

// In middleware:
if (isWhitelisted(ip)) {
  // Skip rate limiting for whitelisted IPs
  return { allowed: true, ... }
}
```

**Risk 2: Distributed Attacks (Many IPs)**

**Mitigation:**
1. Rate limit by endpoint globally (not just per-IP)
2. Implement CAPTCHA for repeated 429s
3. Add IP reputation checking (future)

**Implementation:**
```typescript
// Add global rate limiting
const GLOBAL_RATE_LIMITS = {
  'matrix/command': { maxRequests: 1000, windowMs: 60000 }, // Total across all IPs
}

// Check global limit before per-IP limit
```

**Risk 3: Legitimate Bursts (Bartender switching many TVs)**

**Mitigation:**
1. Use generous limits (60 req/min for hardware)
2. Implement token bucket algorithm (future enhancement)
3. Allow burst buffer (future enhancement)

**Risk 4: Rate Limiter Memory Leak**

**Mitigation:**
1. ‚úÖ Already has automatic cleanup (every 5 minutes)
2. ‚úÖ Limits tracked per IP (bounded memory)
3. Add memory monitoring (Task 10)

---

### Rollback Plan

**If rate limiting causes issues:**

**Option 1: Disable Rate Limiting Globally (Emergency)**
```typescript
// /src/lib/rate-limiting/middleware.ts
export async function withRateLimit(request: NextRequest, tier: string) {
  // EMERGENCY BYPASS
  return { allowed: true, remaining: 9999, ... }
}
```

**Time to rollback:** 1 minute (edit 1 file)
**Impact:** All rate limiting disabled, system unprotected

**Option 2: Disable Per-Endpoint**
```typescript
// Remove rate limit check from problematic endpoint
// export async function POST(request: NextRequest) {
//   const rateLimitCheck = await withRateLimit(request, 'HARDWARE')
//   if (!rateLimitCheck.allowed) return rateLimitCheck.response!
```

**Time to rollback:** 2-5 minutes per endpoint
**Impact:** Specific endpoint unprotected

**Option 3: Increase Limits Temporarily**
```typescript
// /src/lib/rate-limiting/rate-limiter.ts
HARDWARE: {
  maxRequests: 600, // Increased from 60
  windowMs: 60 * 1000,
}
```

**Time to adjust:** 1 minute (edit 1 file, restart)
**Impact:** Higher limits, less protection but fewer false positives

---

### Success Criteria (Checklist)

- [ ] **All 254 unprotected endpoints have rate limiting**
  - Verified by: `grep -r "withRateLimit" src/app/api | wc -l` = 254

- [ ] **Rate limit headers present in all responses**
  - Verified by: `curl -v [endpoint] | grep X-RateLimit`

- [ ] **429 responses formatted correctly**
  - Verified by: Hit limit, check JSON response format

- [ ] **Different tiers have correct limits**
  - Verified by: Test each tier, count requests before 429

- [ ] **No false positives after 48 hours**
  - Verified by: Review logs, no legitimate users blocked

- [ ] **Performance overhead acceptable (<1ms)**
  - Verified by: Before/after response time comparison

- [ ] **Documentation updated**
  - Verified by: API-RATE-LIMITS.md exists and is complete

- [ ] **Clients notified**
  - Verified by: Email sent, support tickets monitored

- [ ] **Monitoring in place**
  - Verified by: Rate limit stats endpoint working

- [ ] **Rollback plan tested**
  - Verified by: Can disable rate limiting in <2 minutes

---

### Time Breakdown

| Step | Time | Cumulative |
|------|------|------------|
| 1. Endpoint Inventory & Categorization | 1-2 hours | 1-2 hours |
| 2. Create Batch Update Script | 1 hour | 2-3 hours |
| 3. Manual Review & Special Cases | 1-2 hours | 3-5 hours |
| 4. Integration Testing | 1 hour | 4-6 hours |
| 5. Monitoring & Adjustment Setup | 1-2 hours | 5-8 hours |
| 6. Documentation & Communication | 1 hour | 6-9 hours |
| **Total** | **6-9 hours** | |
| + 48 hours observation | (passive) | |

**Revised Estimate:** 6-9 hours active work + 48 hours passive monitoring

---

## 5. ALTERNATIVE APPROACHES FOR RATE LIMITING

### Approach A: Middleware-Based (Current Recommendation)

**Description:** Add rate limiting check at the start of each route handler

```typescript
export async function POST(request: NextRequest) {
  const rateLimitCheck = await withRateLimit(request, 'HARDWARE')
  if (!rateLimitCheck.allowed) return rateLimitCheck.response!

  // ... rest of handler
}
```

**Pros:**
- ‚úÖ Simple to implement
- ‚úÖ Works with existing code
- ‚úÖ No Next.js version dependencies
- ‚úÖ Per-endpoint control (can customize limits)
- ‚úÖ Clear and explicit (easy to see rate limiting in code)

**Cons:**
- ‚ùå Repetitive code (must add to each endpoint)
- ‚ùå Easy to forget on new endpoints
- ‚ùå 254 files to modify

**Time:** 6-9 hours
**Risk:** Low
**Maintainability:** Medium (must remember to add to new endpoints)

---

### Approach B: Next.js Middleware (Global)

**Description:** Use Next.js middleware.ts to apply rate limiting globally

```typescript
// /src/middleware.ts
import { NextRequest, NextResponse } from 'next/server'
import { withRateLimit } from '@/lib/rate-limiting/middleware'

export async function middleware(request: NextRequest) {
  // Determine tier based on URL
  const tier = getTierForPath(request.nextUrl.pathname)

  if (tier) {
    const rateLimitCheck = await withRateLimit(request, tier)
    if (!rateLimitCheck.allowed) {
      return rateLimitCheck.response!
    }
  }

  return NextResponse.next()
}

export const config = {
  matcher: '/api/:path*' // Apply to all API routes
}

function getTierForPath(pathname: string): string | null {
  if (pathname.startsWith('/api/health')) return null // No rate limiting
  if (pathname.startsWith('/api/matrix')) return 'HARDWARE'
  if (pathname.startsWith('/api/ai')) return 'AI'
  // ... more rules
}
```

**Pros:**
- ‚úÖ Single place to manage rate limiting
- ‚úÖ Automatic for all current and future endpoints
- ‚úÖ No need to modify 254 files
- ‚úÖ Centralized configuration

**Cons:**
- ‚ùå Less flexible (harder to customize per-endpoint)
- ‚ùå Tier determination logic can get complex
- ‚ùå Harder to debug (middleware runs before route handler)
- ‚ùå May impact performance (runs on every request)

**Time:** 3-4 hours
**Risk:** Medium
**Maintainability:** High (centralized)

---

### Approach C: Hybrid (Global Middleware + Endpoint Override)

**Description:** Use middleware for default rate limiting, allow endpoints to override

```typescript
// /src/middleware.ts - Default rate limiting
export async function middleware(request: NextRequest) {
  // Apply DEFAULT tier by default
  const rateLimitCheck = await withRateLimit(request, 'DEFAULT')
  if (!rateLimitCheck.allowed) {
    return rateLimitCheck.response!
  }

  return NextResponse.next()
}

// Individual routes can override
export async function POST(request: NextRequest) {
  // Override with stricter limit
  const rateLimitCheck = await withRateLimit(request, 'EXPENSIVE')
  if (!rateLimitCheck.allowed) return rateLimitCheck.response!

  // ... rest
}
```

**Pros:**
- ‚úÖ Best of both worlds
- ‚úÖ Default protection for all endpoints
- ‚úÖ Flexibility for special cases

**Cons:**
- ‚ùå Slightly complex (two places to check)
- ‚ùå Risk of double rate limiting (need to handle)

**Time:** 4-5 hours
**Risk:** Medium
**Maintainability:** High

---

### Approach D: Decorator Pattern (Future Enhancement)

**Description:** Use TypeScript decorators to add rate limiting declaratively

```typescript
@RateLimit('HARDWARE')
export async function POST(request: NextRequest) {
  // ... handler logic
}
```

**Pros:**
- ‚úÖ Very clean syntax
- ‚úÖ Clear intent
- ‚úÖ Easy to add to new endpoints

**Cons:**
- ‚ùå TypeScript decorators are experimental
- ‚ùå Requires build tooling changes
- ‚ùå Not compatible with Next.js App Router (function exports)
- ‚ùå High complexity to implement

**Time:** 12-16 hours
**Risk:** High
**Maintainability:** High (if working)

---

### Recommended Approach: **A (Middleware-Based)**

**Why:**
1. **Proven Pattern** - Already working in 2 endpoints
2. **Low Risk** - Doesn't change Next.js architecture
3. **Explicit** - Clear in code what rate limit applies
4. **Flexible** - Easy to customize per-endpoint
5. **Debuggable** - Easy to test and troubleshoot

**When to Consider Approach B or C:**
- After initial rollout is complete
- If maintaining 254 files becomes burdensome
- If many new endpoints are added frequently

---

## 6. RESOURCE REQUIREMENTS

### For Rate Limiting Rollout (Task #1)

**Time Needed:** 6-9 hours active work + 48 hours passive monitoring

**Personnel:**
- 1 developer (full-time for 1-2 days)
- 1 reviewer (for code review, 1-2 hours)
- 1 QA tester (optional, for integration testing, 2-3 hours)

**Files to Modify:** ~254 API route files + 1 documentation file

**Tests to Write:**
- 0 new tests (rate limiter already tested)
- Update existing integration tests to handle 429 responses

**Documentation to Update:**
- Create: `API-RATE-LIMITS.md` (new file)
- Update: `README.md` (add rate limiting section)
- Update: Frontend error handling documentation

**Dependencies to Install:** None (already have everything)

**Infrastructure Changes:** None

**Breaking Changes:** No (rate limits are high enough to not affect legitimate use)

**Backward Compatibility:** 100% (all existing clients continue to work)

---

### For All 11 Tasks (Full Implementation)

**Total Time Estimate:** 150-250 hours

**Breakdown:**
| Phase | Tasks | Time | Personnel |
|-------|-------|------|-----------|
| Phase 1 | Rate Limiting | 6-9 hours | 1 dev |
| Phase 2 | Quick Wins | 6-8 hours | 1-2 devs (parallel) |
| Phase 3 | N+1 Optimization | 6-8 hours | 1 dev |
| Phase 4 | Input Validation | 12-20 hours | 1-2 devs |
| Phase 5 | Auth/Authz | 16-24 hours | 1-2 devs |
| Phase 6 | Encryption | 12-18 hours | 1 dev |
| Phase 7 | Tests + TypeScript | 50-70 hours | 1-2 devs |
| Phase 8 | Monitoring | 16-24 hours | 1 dev |
| **Total** | | **124-181 hours** | |

**Realistic Timeline with 2 Developers:**
- **Weeks 1-2:** Phases 1-3 (security foundation + quick wins)
- **Weeks 3-4:** Phase 4 (input validation)
- **Weeks 5-6:** Phase 5 (authentication)
- **Week 7:** Phase 6 (encryption)
- **Weeks 8-12:** Phase 7 (tests + TypeScript, ongoing)
- **Week 13:** Phase 8 (monitoring)

**Total Duration:** ~13 weeks (3 months) with 2 developers

---

## 7. SUCCESS CRITERIA

### Overall Success Criteria

**System will be considered production-ready when:**

- [ ] **Security:**
  - [ ] 100% of API endpoints have rate limiting
  - [ ] 90%+ of endpoints have input validation
  - [ ] Authentication system implemented with RBAC
  - [ ] Sensitive data encrypted at rest
  - [ ] TLS enforced for all connections

- [ ] **Performance:**
  - [ ] <100ms average API response time
  - [ ] <50ms for cached responses
  - [ ] 50%+ reduction in database queries
  - [ ] 70%+ cache hit rate for frequently accessed data

- [ ] **Code Quality:**
  - [ ] TypeScript strict mode enabled
  - [ ] 80%+ test coverage
  - [ ] 0 `console.*` statements (all using logger)
  - [ ] <100 `any` usages (from 1,346)

- [ ] **Reliability:**
  - [ ] <0.1% error rate
  - [ ] 99.9% uptime
  - [ ] All tests passing
  - [ ] No high-severity bugs

- [ ] **Observability:**
  - [ ] Monitoring dashboards operational
  - [ ] Alerts configured
  - [ ] Structured logging implemented
  - [ ] Performance metrics tracked

---

### Per-Task Success Criteria

#### Task 1: Rate Limiting Rollout

- [ ] 254 endpoints protected (100% coverage)
- [ ] Rate limit headers present
- [ ] <1% false positive rate
- [ ] <1ms performance overhead
- [ ] Documentation complete

#### Task 2: Input Validation

- [ ] 90%+ endpoints validated
- [ ] Zod schemas for all input types
- [ ] Helpful error messages
- [ ] All tests pass
- [ ] No regressions

#### Task 3: Authentication/Authorization

- [ ] Login/logout works
- [ ] RBAC enforced
- [ ] Session management working
- [ ] Audit logging implemented
- [ ] All clients updated

#### Task 4: Encryption

- [ ] All credentials encrypted
- [ ] API keys encrypted
- [ ] TLS enforced
- [ ] Encryption keys backed up
- [ ] Migration successful

#### Task 5: Database Connection Pooling

- [ ] Connection health monitoring
- [ ] Read replica (optional)
- [ ] <5% performance improvement (measured)

#### Task 6: N+1 Query Optimization

- [ ] 50%+ reduction in queries
- [ ] 30%+ faster responses
- [ ] All tests pass
- [ ] API contract maintained

#### Task 7: TypeScript Strict Mode

- [ ] `strict: true` enabled
- [ ] 0 type errors
- [ ] <100 `any` usages
- [ ] All builds succeed

#### Task 8: Unit Tests

- [ ] 80%+ coverage
- [ ] Critical paths tested
- [ ] All tests pass
- [ ] CI/CD integrated

#### Task 9: Structured Logging

- [ ] 0 `console.*` statements
- [ ] All logs structured
- [ ] Log rotation working
- [ ] Log analysis possible

#### Task 10: Monitoring Dashboards

- [ ] Grafana dashboards operational
- [ ] Prometheus metrics collected
- [ ] Alerts configured
- [ ] On-call runbook created

#### Task 11: Test Coverage

- [ ] (Merged with Task 8)

---

## 8. DECISION MATRIX

### Quick Reference for Task Selection

| Task | Impact | Risk | Time | Complexity | Dependencies | Can Start |
|------|--------|------|------|------------|--------------|-----------|
| **1. Rate Limiting** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 6-9h | Low-Med | None | ‚úÖ NOW |
| **2. Input Validation** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 12-20h | High | #1 (rec) | After #1 |
| **3. Auth/Authz** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 16-24h | Very High | #2 | After #2 |
| **4. Encryption** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 12-18h | Med-High | #3 | After #3 |
| **5. DB Pooling** | ‚≠ê‚≠ê | ‚≠ê | 2-4h | Low | None | ‚úÖ NOW |
| **6. N+1 Optimization** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 6-8h | Medium | None | ‚úÖ NOW |
| **7. TypeScript Strict** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 20-60h | Very High | None | ‚úÖ NOW |
| **8. Unit Tests** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 30-40h | Medium | None | ‚úÖ NOW |
| **9. Structured Logging** | ‚≠ê‚≠ê‚≠ê | ‚≠ê | 10-16h | Low-Med | None | ‚úÖ NOW |
| **10. Monitoring** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 16-24h | High | #9 | After #9 |
| **11. Test Coverage** | (Merged with #8) | - | - | - | - | - |

---

### Pros/Cons Comparison

#### Recommended Path: Security-First

**Order:** #1 ‚Üí #2 ‚Üí #3 ‚Üí #4 ‚Üí #6 ‚Üí #9 ‚Üí #7 ‚Üí #8 ‚Üí #10

**Pros:**
- ‚úÖ Addresses critical security issues first
- ‚úÖ Foundation for all other work
- ‚úÖ Clear dependencies (each task builds on previous)
- ‚úÖ Can deploy to production after Phase 5
- ‚úÖ Logical progression (security ‚Üí performance ‚Üí quality)

**Cons:**
- ‚ùå Long time before TypeScript strict mode (tech debt accumulates)
- ‚ùå Auth/encryption are high-risk (breaking changes)
- ‚ùå Tests come late (risky refactoring)

**Time to Production:** 8-10 weeks
**Risk Level:** Medium
**Recommended For:** Production deployment timeline

---

#### Alternative Path: Quality-First

**Order:** #7 ‚Üí #8 ‚Üí #1 ‚Üí #2 ‚Üí #9 ‚Üí #6 ‚Üí #3 ‚Üí #4 ‚Üí #10

**Pros:**
- ‚úÖ TypeScript strict catches bugs early
- ‚úÖ Tests provide safety net for changes
- ‚úÖ No new tech debt
- ‚úÖ Cleaner codebase for security work

**Cons:**
- ‚ùå System vulnerable during quality improvements
- ‚ùå TypeScript strict is time-consuming (blocks other work)
- ‚ùå Longer time to address security issues

**Time to Production:** 12-16 weeks
**Risk Level:** High (security gaps longer)
**Recommended For:** Internal/development systems only

---

#### Alternative Path: Quick Wins First

**Order:** #1 ‚Üí #6 ‚Üí #9 ‚Üí #2 ‚Üí #3 ‚Üí #7 ‚Üí #8 ‚Üí #4 ‚Üí #10

**Pros:**
- ‚úÖ Fast visible improvements (caching, logging)
- ‚úÖ Team morale boost (quick successes)
- ‚úÖ Performance benefits early
- ‚úÖ Lower risk tasks first

**Cons:**
- ‚ùå Auth/encryption delayed
- ‚ùå No clear critical path
- ‚ùå Jumping between domains (security ‚Üí performance ‚Üí quality)

**Time to Production:** 10-12 weeks
**Risk Level:** Medium
**Recommended For:** Systems with tight deadlines

---

### Final Recommendation: **Security-First Path**

**Why:**
- System is currently vulnerable (no rate limiting, no auth)
- Security issues are highest priority for production
- Clear dependencies and logical progression
- Can pause after Phase 5 if needed (production-ready baseline)
- Quality improvements (#7, #8) can continue in parallel

---

## CONCLUSION

The Sports-Bar-TV-Controller system is architecturally sound with excellent infrastructure patterns (caching, FireTV connection management, database design) but requires focused effort on security hardening and code quality improvements.

**Key Takeaways:**

1. **Start with Rate Limiting** - Infrastructure exists, quick to implement, immediate security benefit
2. **Follow Security Critical Path** - Rate limiting ‚Üí Validation ‚Üí Auth ‚Üí Encryption
3. **Parallelize Where Possible** - Performance optimizations (#6, #9) can run alongside security work
4. **Invest in Quality** - TypeScript strict mode and tests provide long-term ROI
5. **Monitor Progress** - Success criteria and metrics are well-defined

**Next Immediate Actions:**

1. **Today:** Review this analysis with team
2. **Day 1:** Start Task #1 (Rate Limiting Rollout)
3. **Day 2-3:** Complete rate limiting, begin monitoring
4. **Week 2:** Start Task #2 (Input Validation)
5. **Week 3+:** Follow recommended path

**Timeline Summary:**
- **Weeks 1-2:** Security foundation (Phases 1-3)
- **Weeks 3-6:** Security hardening (Phases 4-6)
- **Weeks 7-13:** Quality & observability (Phases 7-8)

**Total Effort:** 150-200 hours (2 developers, 3 months)

**Confidence Level:** HIGH - Analysis based on comprehensive code review, existing patterns, and proven strategies.

---

**Document Prepared By:** Claude Code (System Guardian)
**Analysis Date:** November 3, 2025
**Last Updated:** November 3, 2025
**Version:** 1.0

---

## APPENDIX

### A. API Endpoint Inventory Template

```
# api-endpoints-inventory.txt

## Hardware Control (HARDWARE tier - 60 req/min)
/api/matrix/command - POST
/api/matrix/switch-input-enhanced - POST
... (continue for all)

## Authentication (AUTH tier - 10 req/min)
/api/auth/login - POST (future)
... (continue for all)

(Complete list of 256 endpoints)
```

### B. Rate Limiting Configuration Reference

```typescript
// /src/lib/rate-limiting/rate-limiter.ts

export const RateLimitConfigs = {
  DEFAULT: { maxRequests: 10, windowMs: 60000, identifier: 'default' },
  AI: { maxRequests: 5, windowMs: 60000, identifier: 'ai' },
  SPORTS: { maxRequests: 20, windowMs: 60000, identifier: 'sports' },
  EXPENSIVE: { maxRequests: 2, windowMs: 60000, identifier: 'expensive' },
  HARDWARE: { maxRequests: 60, windowMs: 60000, identifier: 'hardware' },
  AUTH: { maxRequests: 10, windowMs: 60000, identifier: 'auth' }
}
```

### C. Testing Checklist Template

```markdown
## Rate Limiting Test Checklist

- [ ] All endpoints return X-RateLimit-* headers
- [ ] 429 responses after hitting limit
- [ ] Rate limits reset after window
- [ ] Different tiers have correct limits
- [ ] Hardware endpoints: 60 req/min
- [ ] AI endpoints: 5 req/min
- [ ] Sports endpoints: 20 req/min
- [ ] Default endpoints: 10 req/min
- [ ] Health/metrics not rate limited
- [ ] No false positives (legitimate traffic)
- [ ] Performance overhead <1ms
- [ ] Load testing passed (100 concurrent users)
```

### D. Monitoring Queries

```bash
# Rate limit hit rate
grep "Rate limit exceeded" logs/all-operations.log | wc -l

# Top blocked IPs
grep "Rate limit exceeded" logs/all-operations.log | \
  jq -r '.ip' | sort | uniq -c | sort -rn | head -20

# Rate limits by endpoint
grep "Rate limit exceeded" logs/all-operations.log | \
  jq -r '.identifier' | sort | uniq -c | sort -rn

# Success vs blocked ratio
TOTAL=$(grep "API request" logs/all-operations.log | wc -l)
BLOCKED=$(grep "Rate limit exceeded" logs/all-operations.log | wc -l)
echo "Block rate: $(echo "scale=2; $BLOCKED / $TOTAL * 100" | bc)%"
```

### E. Useful Commands

```bash
# Count API endpoints
find src/app/api -name "route.ts" | wc -l

# Count endpoints with rate limiting
grep -r "withRateLimit" src/app/api --include="*.ts" | wc -l

# Count console.log statements
grep -r "console\." src --include="*.ts" | wc -l

# Count 'any' usages
grep -r ": any" src --include="*.ts" | wc -l

# Check TypeScript errors
npx tsc --noEmit | grep "error TS" | wc -l

# Test coverage
npm run test:coverage | grep "% Statements"
```
